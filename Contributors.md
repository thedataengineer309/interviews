# Guide to the contributors

Who can contribute: All roles related to data engineering irrespective of any cloud.
Simply create a text file with filename as `company_role_experience_month_year_of_interview`.txt
Save this file in a first letter of the company folder. Create one if there isn't.

For example: If you have given TCS interview for AWS data engineer with experience of 5 years in july 2025 then create a file as `TCS_awsdataengineer_5y_july25.txt`. 
Save this inside `T` folder. If there is no `T` folder, create one. This will help another company, lets say one of you given the interview for `Target` then you can add the files in `T` folder.

# What to write:
Simply write the questions asked for you in the interview.
Write the approach, important points to cover.

For example:

Describe Spark architecture

Approach: Tell about architecture: Driver, cluster manager, executors.

Thats it.

While making a commit, keep any commit message of your choice.
Push the code. I will merge to main within 24 hours.


Fork now and be a helping hand for the community.
Thanks
